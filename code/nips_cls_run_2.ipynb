{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Classification (MNIST) Tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Packages loaded.\n"
     ]
    }
   ],
   "source": [
    "import nbloader\n",
    "from nips_cls_config_2 import worker_class\n",
    "if __name__ == \"__main__\": \n",
    "    print (\"Packages loaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate Workers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Worker_00] Instantiated.\n"
     ]
    }
   ],
   "source": [
    "nWorker = 1\n",
    "maxGPU  = 1\n",
    "WORKERS = ['']*nWorker\n",
    "for i in range(nWorker):\n",
    "    WORKERS[i] = worker_class(_idx=i,_maxProcessID=nWorker,_maxGPU=maxGPU,_name='Worker_%02d'%(i)\n",
    "                              ,_period=1.0,_maxTick=10,_VERBOSE=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start Workers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting [Worker_00]\n",
      "processID:[0/1] GPU_ID:[0] #Config:[6]\n",
      "WARNING:tensorflow:From <string>:2: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ../data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ../data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting ../data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ../data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From <string>:224: calling softmax (from tensorflow.python.ops.nn_ops) with dim is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "dim is deprecated, use axis instead\n",
      "Text name: ../res/res_mnist_rs_err90_basic_kmix2_choiceNet.txt\n",
      "[00/40] [Loss] train:0.033(f:-0.123+r:0.041+k:0.000+l:0.116) val:-0.147 test:-0.160 [Accr] train:15.3% val:58.6% test:60.7% maxVal:58.6% maxTest:60.7%\n",
      "[01/40] [Loss] train:0.022(f:-0.137+r:0.043+k:0.000+l:0.115) val:-0.284 test:-0.293 [Accr] train:17.1% val:78.8% test:79.3% maxVal:78.8% maxTest:79.3%\n",
      "[02/40] [Loss] train:0.016(f:-0.144+r:0.045+k:0.000+l:0.115) val:-0.355 test:-0.360 [Accr] train:17.9% val:85.5% test:85.6% maxVal:85.5% maxTest:85.6%\n",
      "[03/40] [Loss] train:0.013(f:-0.148+r:0.046+k:0.000+l:0.115) val:-0.388 test:-0.395 [Accr] train:18.1% val:88.6% test:88.9% maxVal:88.6% maxTest:88.9%\n",
      "[04/40] [Loss] train:0.010(f:-0.151+r:0.046+k:0.000+l:0.115) val:-0.408 test:-0.416 [Accr] train:18.4% val:90.4% test:90.7% maxVal:90.4% maxTest:90.7%\n",
      "[05/40] [Loss] train:0.007(f:-0.153+r:0.045+k:0.000+l:0.115) val:-0.424 test:-0.429 [Accr] train:18.5% val:91.9% test:92.0% maxVal:91.9% maxTest:92.0%\n",
      "[06/40] [Loss] train:0.004(f:-0.154+r:0.044+k:0.000+l:0.115) val:-0.428 test:-0.437 [Accr] train:18.7% val:92.9% test:92.9% maxVal:92.9% maxTest:92.9%\n",
      "[07/40] [Loss] train:0.002(f:-0.157+r:0.044+k:0.000+l:0.115) val:-0.448 test:-0.455 [Accr] train:18.8% val:92.9% test:93.4% maxVal:92.9% maxTest:93.4%\n",
      "[08/40] [Loss] train:0.001(f:-0.157+r:0.043+k:0.000+l:0.114) val:-0.456 test:-0.454 [Accr] train:18.8% val:93.5% test:93.7% maxVal:93.5% maxTest:93.7%\n",
      "[09/40] [Loss] train:-0.001(f:-0.158+r:0.042+k:0.000+l:0.114) val:-0.450 test:-0.453 [Accr] train:18.9% val:94.1% test:94.2% maxVal:94.1% maxTest:94.2%\n",
      "[10/40] [Loss] train:-0.001(f:-0.158+r:0.042+k:0.000+l:0.114) val:-0.452 test:-0.454 [Accr] train:19.0% val:94.4% test:94.6% maxVal:94.4% maxTest:94.6%\n",
      "[11/40] [Loss] train:-0.004(f:-0.159+r:0.041+k:0.000+l:0.114) val:-0.451 test:-0.455 [Accr] train:19.1% val:94.3% test:94.6% maxVal:94.4% maxTest:94.6%\n",
      "[12/40] [Loss] train:-0.007(f:-0.162+r:0.041+k:0.000+l:0.114) val:-0.463 test:-0.468 [Accr] train:19.1% val:94.2% test:94.7% maxVal:94.4% maxTest:94.6%\n",
      "[13/40] [Loss] train:-0.007(f:-0.161+r:0.040+k:0.000+l:0.114) val:-0.458 test:-0.461 [Accr] train:19.2% val:94.8% test:95.0% maxVal:94.8% maxTest:95.0%\n",
      "[14/40] [Loss] train:-0.010(f:-0.163+r:0.039+k:0.000+l:0.113) val:-0.468 test:-0.467 [Accr] train:19.3% val:94.3% test:94.9% maxVal:94.8% maxTest:95.0%\n",
      "[15/40] [Loss] train:-0.011(f:-0.163+r:0.038+k:0.000+l:0.113) val:-0.460 test:-0.466 [Accr] train:19.3% val:94.7% test:95.0% maxVal:94.8% maxTest:95.0%\n",
      "[16/40] [Loss] train:-0.016(f:-0.166+r:0.037+k:0.000+l:0.113) val:-0.468 test:-0.472 [Accr] train:19.4% val:94.5% test:94.8% maxVal:94.8% maxTest:95.0%\n",
      "[17/40] [Loss] train:-0.015(f:-0.165+r:0.037+k:0.000+l:0.113) val:-0.466 test:-0.472 [Accr] train:19.4% val:94.4% test:94.9% maxVal:94.8% maxTest:95.0%\n",
      "[18/40] [Loss] train:-0.018(f:-0.167+r:0.036+k:0.000+l:0.113) val:-0.469 test:-0.473 [Accr] train:19.6% val:94.7% test:94.7% maxVal:94.8% maxTest:95.0%\n",
      "[19/40] [Loss] train:-0.018(f:-0.166+r:0.035+k:0.000+l:0.113) val:-0.458 test:-0.465 [Accr] train:19.6% val:94.7% test:95.1% maxVal:94.8% maxTest:95.0%\n",
      "[20/40] [Loss] train:-0.020(f:-0.168+r:0.035+k:0.000+l:0.113) val:-0.471 test:-0.470 [Accr] train:19.6% val:94.7% test:95.1% maxVal:94.8% maxTest:95.0%\n",
      "[21/40] [Loss] train:-0.020(f:-0.168+r:0.035+k:0.000+l:0.113) val:-0.466 test:-0.470 [Accr] train:19.6% val:94.7% test:95.1% maxVal:94.8% maxTest:95.0%\n",
      "[22/40] [Loss] train:-0.020(f:-0.167+r:0.035+k:0.000+l:0.113) val:-0.463 test:-0.467 [Accr] train:19.6% val:94.7% test:95.0% maxVal:94.8% maxTest:95.0%\n",
      "[23/40] [Loss] train:-0.021(f:-0.169+r:0.035+k:0.000+l:0.113) val:-0.466 test:-0.468 [Accr] train:19.6% val:94.7% test:95.1% maxVal:94.8% maxTest:95.0%\n",
      "[24/40] [Loss] train:-0.021(f:-0.168+r:0.035+k:0.000+l:0.113) val:-0.462 test:-0.469 [Accr] train:19.6% val:94.8% test:95.0% maxVal:94.8% maxTest:95.0%\n",
      "[25/40] [Loss] train:-0.021(f:-0.168+r:0.035+k:0.000+l:0.113) val:-0.463 test:-0.466 [Accr] train:19.7% val:94.7% test:95.0% maxVal:94.8% maxTest:95.0%\n",
      "[26/40] [Loss] train:-0.022(f:-0.169+r:0.035+k:0.000+l:0.113) val:-0.470 test:-0.472 [Accr] train:19.7% val:94.7% test:94.9% maxVal:94.8% maxTest:95.0%\n",
      "[27/40] [Loss] train:-0.022(f:-0.169+r:0.035+k:0.000+l:0.113) val:-0.466 test:-0.470 [Accr] train:19.7% val:94.7% test:94.9% maxVal:94.8% maxTest:95.0%\n",
      "[28/40] [Loss] train:-0.023(f:-0.170+r:0.035+k:0.000+l:0.113) val:-0.464 test:-0.466 [Accr] train:19.7% val:94.6% test:94.9% maxVal:94.8% maxTest:95.0%\n",
      "[29/40] [Loss] train:-0.023(f:-0.170+r:0.034+k:0.000+l:0.113) val:-0.461 test:-0.465 [Accr] train:19.7% val:94.5% test:95.0% maxVal:94.8% maxTest:95.0%\n",
      "[30/40] [Loss] train:-0.023(f:-0.170+r:0.034+k:0.000+l:0.113) val:-0.466 test:-0.468 [Accr] train:19.8% val:94.6% test:94.8% maxVal:94.8% maxTest:95.0%\n",
      "[31/40] [Loss] train:-0.023(f:-0.170+r:0.034+k:0.000+l:0.113) val:-0.459 test:-0.464 [Accr] train:19.8% val:94.6% test:94.9% maxVal:94.8% maxTest:95.0%\n",
      "[32/40] [Loss] train:-0.023(f:-0.170+r:0.034+k:0.000+l:0.113) val:-0.465 test:-0.466 [Accr] train:19.8% val:94.6% test:94.9% maxVal:94.8% maxTest:95.0%\n",
      "[33/40] [Loss] train:-0.023(f:-0.170+r:0.034+k:0.000+l:0.113) val:-0.463 test:-0.467 [Accr] train:19.8% val:94.7% test:94.9% maxVal:94.8% maxTest:95.0%\n",
      "[34/40] [Loss] train:-0.023(f:-0.170+r:0.034+k:0.000+l:0.113) val:-0.462 test:-0.467 [Accr] train:19.8% val:94.7% test:94.8% maxVal:94.8% maxTest:95.0%\n",
      "[35/40] [Loss] train:-0.022(f:-0.169+r:0.034+k:0.000+l:0.113) val:-0.460 test:-0.464 [Accr] train:19.7% val:94.6% test:94.8% maxVal:94.8% maxTest:95.0%\n",
      "[36/40] [Loss] train:-0.023(f:-0.170+r:0.034+k:0.000+l:0.113) val:-0.462 test:-0.462 [Accr] train:19.8% val:94.6% test:94.9% maxVal:94.8% maxTest:95.0%\n",
      "[37/40] [Loss] train:-0.024(f:-0.171+r:0.034+k:0.000+l:0.113) val:-0.465 test:-0.466 [Accr] train:19.8% val:94.7% test:94.9% maxVal:94.8% maxTest:95.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[38/40] [Loss] train:-0.024(f:-0.171+r:0.034+k:0.000+l:0.113) val:-0.463 test:-0.466 [Accr] train:19.8% val:94.7% test:94.9% maxVal:94.8% maxTest:95.0%\n",
      "[39/40] [Loss] train:-0.022(f:-0.170+r:0.035+k:0.000+l:0.113) val:-0.458 test:-0.463 [Accr] train:19.8% val:94.7% test:95.0% maxVal:94.8% maxTest:95.0%\n",
      "[40/40] [Loss] train:-0.023(f:-0.170+r:0.034+k:0.000+l:0.113) val:-0.463 test:-0.466 [Accr] train:19.8% val:94.6% test:94.8% maxVal:94.8% maxTest:95.0%\n",
      "Training finished.\n",
      "Extracting ../data/train-images-idx3-ubyte.gz\n",
      "Extracting ../data/train-labels-idx1-ubyte.gz\n",
      "Extracting ../data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ../data/t10k-labels-idx1-ubyte.gz\n",
      "Text name: ../res/res_mnist_rs_err90_basic_kmix3_choiceNet.txt\n",
      "[00/40] [Loss] train:0.043(f:-0.116+r:0.043+k:0.000+l:0.116) val:-0.087 test:-0.097 [Accr] train:15.0% val:54.4% test:56.6% maxVal:54.4% maxTest:56.6%\n",
      "[01/40] [Loss] train:0.032(f:-0.129+r:0.046+k:0.000+l:0.115) val:-0.214 test:-0.220 [Accr] train:17.0% val:76.9% test:77.6% maxVal:76.9% maxTest:77.6%\n",
      "[02/40] [Loss] train:0.025(f:-0.137+r:0.047+k:0.000+l:0.115) val:-0.279 test:-0.288 [Accr] train:17.8% val:83.7% test:84.1% maxVal:83.7% maxTest:84.1%\n",
      "[03/40] [Loss] train:0.022(f:-0.141+r:0.047+k:0.000+l:0.115) val:-0.306 test:-0.320 [Accr] train:18.0% val:87.1% test:87.4% maxVal:87.1% maxTest:87.4%\n",
      "[04/40] [Loss] train:0.020(f:-0.143+r:0.048+k:0.000+l:0.115) val:-0.329 test:-0.337 [Accr] train:18.3% val:89.3% test:89.5% maxVal:89.3% maxTest:89.5%\n",
      "[05/40] [Loss] train:0.017(f:-0.145+r:0.047+k:0.000+l:0.115) val:-0.348 test:-0.355 [Accr] train:18.3% val:90.9% test:90.6% maxVal:90.9% maxTest:90.6%\n",
      "[06/40] [Loss] train:0.015(f:-0.147+r:0.047+k:0.000+l:0.115) val:-0.359 test:-0.367 [Accr] train:18.5% val:91.8% test:91.9% maxVal:91.8% maxTest:91.9%\n",
      "[07/40] [Loss] train:0.013(f:-0.148+r:0.047+k:0.000+l:0.115) val:-0.369 test:-0.378 [Accr] train:18.6% val:92.5% test:92.5% maxVal:92.5% maxTest:92.5%\n",
      "[08/40] [Loss] train:0.012(f:-0.149+r:0.046+k:0.000+l:0.114) val:-0.379 test:-0.384 [Accr] train:18.7% val:92.9% test:92.9% maxVal:92.9% maxTest:92.9%\n",
      "[09/40] [Loss] train:0.009(f:-0.151+r:0.046+k:0.000+l:0.114) val:-0.380 test:-0.389 [Accr] train:18.8% val:93.7% test:93.6% maxVal:93.7% maxTest:93.6%\n",
      "[10/40] [Loss] train:0.007(f:-0.152+r:0.044+k:0.000+l:0.114) val:-0.383 test:-0.392 [Accr] train:18.8% val:93.9% test:93.7% maxVal:93.9% maxTest:93.7%\n",
      "[11/40] [Loss] train:0.006(f:-0.153+r:0.044+k:0.000+l:0.114) val:-0.393 test:-0.400 [Accr] train:18.9% val:94.2% test:93.9% maxVal:94.2% maxTest:93.9%\n",
      "[12/40] [Loss] train:0.004(f:-0.154+r:0.044+k:0.000+l:0.114) val:-0.394 test:-0.404 [Accr] train:19.0% val:94.0% test:94.3% maxVal:94.2% maxTest:93.9%\n",
      "[13/40] [Loss] train:0.004(f:-0.153+r:0.043+k:0.000+l:0.114) val:-0.388 test:-0.396 [Accr] train:19.0% val:94.5% test:94.5% maxVal:94.5% maxTest:94.5%\n",
      "[14/40] [Loss] train:0.001(f:-0.156+r:0.043+k:0.000+l:0.113) val:-0.396 test:-0.404 [Accr] train:19.0% val:94.2% test:94.6% maxVal:94.5% maxTest:94.5%\n",
      "[15/40] [Loss] train:-0.001(f:-0.156+r:0.042+k:0.000+l:0.113) val:-0.407 test:-0.410 [Accr] train:19.1% val:94.5% test:94.7% maxVal:94.5% maxTest:94.7%\n",
      "[16/40] [Loss] train:-0.002(f:-0.156+r:0.041+k:0.000+l:0.113) val:-0.404 test:-0.408 [Accr] train:19.2% val:94.6% test:94.6% maxVal:94.6% maxTest:94.6%\n",
      "[17/40] [Loss] train:-0.004(f:-0.157+r:0.040+k:0.000+l:0.113) val:-0.404 test:-0.412 [Accr] train:19.2% val:94.6% test:94.8% maxVal:94.6% maxTest:94.8%\n",
      "[18/40] [Loss] train:-0.007(f:-0.160+r:0.039+k:0.000+l:0.113) val:-0.417 test:-0.420 [Accr] train:19.2% val:94.7% test:94.9% maxVal:94.7% maxTest:94.9%\n",
      "[19/40] [Loss] train:-0.008(f:-0.159+r:0.039+k:0.000+l:0.113) val:-0.412 test:-0.425 [Accr] train:19.3% val:94.8% test:95.1% maxVal:94.8% maxTest:95.1%\n",
      "[20/40] [Loss] train:-0.008(f:-0.159+r:0.039+k:0.000+l:0.113) val:-0.414 test:-0.416 [Accr] train:19.3% val:94.8% test:95.1% maxVal:94.8% maxTest:95.1%\n",
      "[21/40] [Loss] train:-0.009(f:-0.160+r:0.039+k:0.000+l:0.113) val:-0.411 test:-0.418 [Accr] train:19.3% val:94.7% test:95.1% maxVal:94.8% maxTest:95.1%\n",
      "[22/40] [Loss] train:-0.009(f:-0.160+r:0.038+k:0.000+l:0.113) val:-0.415 test:-0.420 [Accr] train:19.3% val:94.7% test:95.1% maxVal:94.8% maxTest:95.1%\n",
      "[23/40] [Loss] train:-0.009(f:-0.161+r:0.039+k:0.000+l:0.113) val:-0.412 test:-0.417 [Accr] train:19.3% val:94.8% test:95.1% maxVal:94.8% maxTest:95.1%\n",
      "[24/40] [Loss] train:-0.009(f:-0.160+r:0.038+k:0.000+l:0.113) val:-0.411 test:-0.417 [Accr] train:19.3% val:94.6% test:95.1% maxVal:94.8% maxTest:95.1%\n",
      "[25/40] [Loss] train:-0.011(f:-0.162+r:0.038+k:0.000+l:0.113) val:-0.414 test:-0.419 [Accr] train:19.4% val:94.7% test:95.0% maxVal:94.8% maxTest:95.1%\n",
      "[26/40] [Loss] train:-0.010(f:-0.161+r:0.038+k:0.000+l:0.113) val:-0.413 test:-0.420 [Accr] train:19.4% val:94.6% test:95.0% maxVal:94.8% maxTest:95.1%\n",
      "[27/40] [Loss] train:-0.009(f:-0.160+r:0.038+k:0.000+l:0.113) val:-0.413 test:-0.418 [Accr] train:19.3% val:94.7% test:95.0% maxVal:94.8% maxTest:95.1%\n",
      "[28/40] [Loss] train:-0.010(f:-0.161+r:0.038+k:0.000+l:0.113) val:-0.408 test:-0.415 [Accr] train:19.4% val:94.6% test:95.1% maxVal:94.8% maxTest:95.1%\n",
      "[29/40] [Loss] train:-0.011(f:-0.162+r:0.038+k:0.000+l:0.113) val:-0.407 test:-0.416 [Accr] train:19.4% val:94.7% test:95.1% maxVal:94.8% maxTest:95.1%\n",
      "[30/40] [Loss] train:-0.010(f:-0.161+r:0.038+k:0.000+l:0.113) val:-0.412 test:-0.415 [Accr] train:19.4% val:94.7% test:95.1% maxVal:94.8% maxTest:95.1%\n",
      "[31/40] [Loss] train:-0.011(f:-0.162+r:0.038+k:0.000+l:0.113) val:-0.411 test:-0.415 [Accr] train:19.4% val:94.6% test:95.1% maxVal:94.8% maxTest:95.1%\n",
      "[32/40] [Loss] train:-0.011(f:-0.161+r:0.038+k:0.000+l:0.113) val:-0.413 test:-0.417 [Accr] train:19.4% val:94.7% test:95.1% maxVal:94.8% maxTest:95.1%\n",
      "[33/40] [Loss] train:-0.010(f:-0.161+r:0.038+k:0.000+l:0.113) val:-0.412 test:-0.419 [Accr] train:19.4% val:94.7% test:95.1% maxVal:94.8% maxTest:95.1%\n",
      "[34/40] [Loss] train:-0.011(f:-0.161+r:0.038+k:0.000+l:0.113) val:-0.412 test:-0.418 [Accr] train:19.4% val:94.7% test:95.1% maxVal:94.8% maxTest:95.1%\n",
      "[35/40] [Loss] train:-0.011(f:-0.162+r:0.038+k:0.000+l:0.113) val:-0.409 test:-0.418 [Accr] train:19.4% val:94.6% test:95.1% maxVal:94.8% maxTest:95.1%\n",
      "[36/40] [Loss] train:-0.011(f:-0.162+r:0.038+k:0.000+l:0.113) val:-0.410 test:-0.413 [Accr] train:19.4% val:94.7% test:95.1% maxVal:94.8% maxTest:95.1%\n",
      "[37/40] [Loss] train:-0.012(f:-0.162+r:0.038+k:0.000+l:0.113) val:-0.414 test:-0.421 [Accr] train:19.4% val:94.7% test:95.1% maxVal:94.8% maxTest:95.1%\n",
      "[38/40] [Loss] train:-0.011(f:-0.162+r:0.038+k:0.000+l:0.113) val:-0.407 test:-0.418 [Accr] train:19.4% val:94.7% test:95.1% maxVal:94.8% maxTest:95.1%\n",
      "[39/40] [Loss] train:-0.010(f:-0.161+r:0.038+k:0.000+l:0.113) val:-0.410 test:-0.417 [Accr] train:19.4% val:94.7% test:95.1% maxVal:94.8% maxTest:95.1%\n",
      "[40/40] [Loss] train:-0.011(f:-0.162+r:0.038+k:0.000+l:0.113) val:-0.415 test:-0.417 [Accr] train:19.4% val:94.6% test:95.1% maxVal:94.8% maxTest:95.1%\n",
      "Training finished.\n",
      "Extracting ../data/train-images-idx3-ubyte.gz\n",
      "Extracting ../data/train-labels-idx1-ubyte.gz\n",
      "Extracting ../data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ../data/t10k-labels-idx1-ubyte.gz\n",
      "Text name: ../res/res_mnist_rs_err90_basic_kmix5_choiceNet.txt\n",
      "[00/40] [Loss] train:0.049(f:-0.113+r:0.046+k:0.000+l:0.116) val:-0.056 test:-0.065 [Accr] train:14.8% val:54.1% test:57.1% maxVal:54.1% maxTest:57.1%\n",
      "[01/40] [Loss] train:0.039(f:-0.125+r:0.048+k:0.000+l:0.115) val:-0.166 test:-0.172 [Accr] train:16.8% val:74.7% test:76.1% maxVal:74.7% maxTest:76.1%\n",
      "[02/40] [Loss] train:0.033(f:-0.132+r:0.049+k:0.000+l:0.115) val:-0.229 test:-0.233 [Accr] train:17.5% val:81.2% test:82.8% maxVal:81.2% maxTest:82.8%\n",
      "[03/40] [Loss] train:0.029(f:-0.136+r:0.049+k:0.000+l:0.115) val:-0.261 test:-0.264 [Accr] train:17.8% val:85.3% test:86.1% maxVal:85.3% maxTest:86.1%\n",
      "[04/40] [Loss] train:0.027(f:-0.138+r:0.049+k:0.000+l:0.115) val:-0.272 test:-0.281 [Accr] train:18.1% val:88.1% test:88.7% maxVal:88.1% maxTest:88.7%\n",
      "[05/40] [Loss] train:0.025(f:-0.139+r:0.049+k:0.000+l:0.115) val:-0.293 test:-0.295 [Accr] train:18.2% val:89.6% test:90.2% maxVal:89.6% maxTest:90.2%\n",
      "[06/40] [Loss] train:0.022(f:-0.141+r:0.049+k:0.000+l:0.115) val:-0.312 test:-0.316 [Accr] train:18.4% val:91.1% test:91.8% maxVal:91.1% maxTest:91.8%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[07/40] [Loss] train:0.021(f:-0.143+r:0.049+k:0.000+l:0.115) val:-0.325 test:-0.328 [Accr] train:18.5% val:92.0% test:92.4% maxVal:92.0% maxTest:92.4%\n",
      "[08/40] [Loss] train:0.019(f:-0.144+r:0.048+k:0.000+l:0.114) val:-0.342 test:-0.342 [Accr] train:18.5% val:92.5% test:92.7% maxVal:92.5% maxTest:92.7%\n",
      "[09/40] [Loss] train:0.017(f:-0.145+r:0.047+k:0.000+l:0.114) val:-0.346 test:-0.341 [Accr] train:18.6% val:93.1% test:93.4% maxVal:93.1% maxTest:93.4%\n",
      "[10/40] [Loss] train:0.015(f:-0.146+r:0.047+k:0.000+l:0.114) val:-0.347 test:-0.350 [Accr] train:18.6% val:93.6% test:93.8% maxVal:93.6% maxTest:93.8%\n",
      "[11/40] [Loss] train:0.014(f:-0.147+r:0.046+k:0.000+l:0.114) val:-0.348 test:-0.351 [Accr] train:18.7% val:93.8% test:94.0% maxVal:93.8% maxTest:94.0%\n",
      "[12/40] [Loss] train:0.011(f:-0.149+r:0.045+k:0.000+l:0.114) val:-0.364 test:-0.364 [Accr] train:18.8% val:94.2% test:94.3% maxVal:94.2% maxTest:94.3%\n",
      "[13/40] [Loss] train:0.010(f:-0.148+r:0.044+k:0.000+l:0.114) val:-0.353 test:-0.356 [Accr] train:18.8% val:94.5% test:94.6% maxVal:94.5% maxTest:94.6%\n",
      "[14/40] [Loss] train:0.008(f:-0.150+r:0.044+k:0.000+l:0.113) val:-0.371 test:-0.367 [Accr] train:18.8% val:94.4% test:94.6% maxVal:94.5% maxTest:94.6%\n",
      "[15/40] [Loss] train:0.006(f:-0.151+r:0.043+k:0.000+l:0.113) val:-0.370 test:-0.370 [Accr] train:18.9% val:94.4% test:94.8% maxVal:94.5% maxTest:94.6%\n",
      "[16/40] [Loss] train:0.003(f:-0.153+r:0.042+k:0.000+l:0.113) val:-0.386 test:-0.384 [Accr] train:19.0% val:94.5% test:94.8% maxVal:94.5% maxTest:94.8%\n",
      "[17/40] [Loss] train:0.003(f:-0.152+r:0.042+k:0.000+l:0.113) val:-0.379 test:-0.378 [Accr] train:18.9% val:94.8% test:94.8% maxVal:94.8% maxTest:94.8%\n",
      "[18/40] [Loss] train:0.001(f:-0.153+r:0.040+k:0.000+l:0.113) val:-0.380 test:-0.381 [Accr] train:19.0% val:95.0% test:95.0% maxVal:95.0% maxTest:95.0%\n",
      "[19/40] [Loss] train:0.001(f:-0.152+r:0.040+k:0.000+l:0.113) val:-0.365 test:-0.370 [Accr] train:19.0% val:95.0% test:95.1% maxVal:95.0% maxTest:95.1%\n",
      "[20/40] [Loss] train:-0.001(f:-0.153+r:0.040+k:0.000+l:0.113) val:-0.385 test:-0.382 [Accr] train:19.1% val:95.1% test:95.1% maxVal:95.1% maxTest:95.1%\n",
      "[21/40] [Loss] train:-0.002(f:-0.154+r:0.040+k:0.000+l:0.113) val:-0.387 test:-0.387 [Accr] train:19.1% val:95.0% test:95.0% maxVal:95.1% maxTest:95.1%\n",
      "[22/40] [Loss] train:-0.002(f:-0.154+r:0.039+k:0.000+l:0.113) val:-0.386 test:-0.386 [Accr] train:19.1% val:95.0% test:95.1% maxVal:95.1% maxTest:95.1%\n",
      "[23/40] [Loss] train:-0.002(f:-0.155+r:0.040+k:0.000+l:0.113) val:-0.386 test:-0.386 [Accr] train:19.1% val:95.0% test:95.1% maxVal:95.1% maxTest:95.1%\n",
      "[24/40] [Loss] train:-0.002(f:-0.154+r:0.039+k:0.000+l:0.113) val:-0.387 test:-0.387 [Accr] train:19.1% val:95.1% test:95.2% maxVal:95.1% maxTest:95.1%\n",
      "[25/40] [Loss] train:-0.002(f:-0.155+r:0.039+k:0.000+l:0.113) val:-0.389 test:-0.383 [Accr] train:19.1% val:95.0% test:95.2% maxVal:95.1% maxTest:95.1%\n",
      "[26/40] [Loss] train:-0.003(f:-0.156+r:0.039+k:0.000+l:0.113) val:-0.390 test:-0.389 [Accr] train:19.1% val:95.0% test:95.1% maxVal:95.1% maxTest:95.1%\n",
      "[27/40] [Loss] train:-0.003(f:-0.155+r:0.039+k:0.000+l:0.113) val:-0.384 test:-0.385 [Accr] train:19.1% val:95.0% test:95.2% maxVal:95.1% maxTest:95.1%\n",
      "[28/40] [Loss] train:-0.003(f:-0.155+r:0.039+k:0.000+l:0.113) val:-0.382 test:-0.385 [Accr] train:19.1% val:94.9% test:95.2% maxVal:95.1% maxTest:95.1%\n",
      "[29/40] [Loss] train:-0.004(f:-0.156+r:0.039+k:0.000+l:0.113) val:-0.385 test:-0.387 [Accr] train:19.1% val:95.1% test:95.2% maxVal:95.1% maxTest:95.1%\n",
      "[30/40] [Loss] train:-0.004(f:-0.156+r:0.039+k:0.000+l:0.113) val:-0.389 test:-0.387 [Accr] train:19.1% val:95.0% test:95.1% maxVal:95.1% maxTest:95.1%\n",
      "[31/40] [Loss] train:-0.004(f:-0.156+r:0.039+k:0.000+l:0.113) val:-0.386 test:-0.386 [Accr] train:19.1% val:95.1% test:95.1% maxVal:95.1% maxTest:95.1%\n",
      "[32/40] [Loss] train:-0.003(f:-0.155+r:0.039+k:0.000+l:0.113) val:-0.388 test:-0.388 [Accr] train:19.1% val:95.0% test:95.2% maxVal:95.1% maxTest:95.1%\n",
      "[33/40] [Loss] train:-0.003(f:-0.155+r:0.039+k:0.000+l:0.113) val:-0.385 test:-0.387 [Accr] train:19.1% val:95.0% test:95.1% maxVal:95.1% maxTest:95.1%\n",
      "[34/40] [Loss] train:-0.004(f:-0.156+r:0.039+k:0.000+l:0.113) val:-0.388 test:-0.386 [Accr] train:19.1% val:95.1% test:95.1% maxVal:95.1% maxTest:95.1%\n",
      "[35/40] [Loss] train:-0.003(f:-0.155+r:0.039+k:0.000+l:0.113) val:-0.385 test:-0.386 [Accr] train:19.1% val:95.0% test:95.2% maxVal:95.1% maxTest:95.1%\n",
      "[36/40] [Loss] train:-0.004(f:-0.156+r:0.039+k:0.000+l:0.113) val:-0.386 test:-0.386 [Accr] train:19.1% val:95.0% test:95.1% maxVal:95.1% maxTest:95.1%\n",
      "[37/40] [Loss] train:-0.004(f:-0.156+r:0.039+k:0.000+l:0.113) val:-0.384 test:-0.386 [Accr] train:19.1% val:95.0% test:95.1% maxVal:95.1% maxTest:95.1%\n",
      "[38/40] [Loss] train:-0.003(f:-0.155+r:0.039+k:0.000+l:0.113) val:-0.383 test:-0.384 [Accr] train:19.1% val:95.1% test:95.1% maxVal:95.1% maxTest:95.1%\n",
      "[39/40] [Loss] train:-0.003(f:-0.155+r:0.039+k:0.000+l:0.113) val:-0.387 test:-0.388 [Accr] train:19.1% val:95.0% test:95.2% maxVal:95.1% maxTest:95.1%\n",
      "[40/40] [Loss] train:-0.003(f:-0.155+r:0.039+k:0.000+l:0.113) val:-0.391 test:-0.386 [Accr] train:19.1% val:95.0% test:95.2% maxVal:95.1% maxTest:95.1%\n",
      "Training finished.\n",
      "Extracting ../data/train-images-idx3-ubyte.gz\n",
      "Extracting ../data/train-labels-idx1-ubyte.gz\n",
      "Extracting ../data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ../data/t10k-labels-idx1-ubyte.gz\n",
      "Text name: ../res/res_mnist_rs_err90_basic_kmix10_choiceNet.txt\n",
      "[00/40] [Loss] train:0.051(f:-0.115+r:0.049+k:0.001+l:0.116) val:-0.059 test:-0.070 [Accr] train:15.3% val:59.2% test:61.3% maxVal:59.2% maxTest:61.3%\n",
      "[01/40] [Loss] train:0.043(f:-0.123+r:0.050+k:0.001+l:0.115) val:-0.150 test:-0.155 [Accr] train:16.9% val:76.7% test:78.2% maxVal:76.7% maxTest:78.2%\n",
      "[02/40] [Loss] train:0.037(f:-0.130+r:0.051+k:0.001+l:0.115) val:-0.208 test:-0.215 [Accr] train:17.6% val:83.4% test:84.1% maxVal:83.4% maxTest:84.1%\n",
      "[03/40] [Loss] train:0.034(f:-0.133+r:0.051+k:0.001+l:0.115) val:-0.235 test:-0.244 [Accr] train:17.8% val:86.3% test:86.6% maxVal:86.3% maxTest:86.6%\n",
      "[04/40] [Loss] train:0.032(f:-0.135+r:0.051+k:0.001+l:0.115) val:-0.253 test:-0.263 [Accr] train:18.1% val:88.3% test:88.4% maxVal:88.3% maxTest:88.4%\n",
      "[05/40] [Loss] train:0.030(f:-0.137+r:0.051+k:0.001+l:0.115) val:-0.278 test:-0.282 [Accr] train:18.2% val:89.8% test:89.7% maxVal:89.8% maxTest:89.7%\n",
      "[06/40] [Loss] train:0.027(f:-0.139+r:0.050+k:0.001+l:0.115) val:-0.288 test:-0.295 [Accr] train:18.3% val:91.3% test:91.1% maxVal:91.3% maxTest:91.1%\n",
      "[07/40] [Loss] train:0.025(f:-0.140+r:0.049+k:0.001+l:0.115) val:-0.300 test:-0.307 [Accr] train:18.5% val:92.0% test:91.9% maxVal:92.0% maxTest:91.9%\n",
      "[08/40] [Loss] train:0.023(f:-0.142+r:0.049+k:0.001+l:0.114) val:-0.317 test:-0.323 [Accr] train:18.5% val:92.6% test:92.3% maxVal:92.6% maxTest:92.3%\n",
      "[09/40] [Loss] train:0.021(f:-0.143+r:0.048+k:0.001+l:0.114) val:-0.323 test:-0.323 [Accr] train:18.6% val:92.9% test:92.7% maxVal:92.9% maxTest:92.7%\n",
      "[10/40] [Loss] train:0.018(f:-0.144+r:0.047+k:0.001+l:0.114) val:-0.335 test:-0.336 [Accr] train:18.6% val:93.4% test:93.2% maxVal:93.4% maxTest:93.2%\n",
      "[11/40] [Loss] train:0.017(f:-0.145+r:0.046+k:0.001+l:0.114) val:-0.332 test:-0.338 [Accr] train:18.7% val:93.5% test:93.5% maxVal:93.5% maxTest:93.5%\n",
      "[12/40] [Loss] train:0.014(f:-0.146+r:0.046+k:0.001+l:0.114) val:-0.339 test:-0.344 [Accr] train:18.8% val:93.9% test:93.7% maxVal:93.9% maxTest:93.7%\n",
      "[13/40] [Loss] train:0.013(f:-0.146+r:0.044+k:0.001+l:0.114) val:-0.336 test:-0.340 [Accr] train:18.8% val:94.1% test:94.1% maxVal:94.1% maxTest:94.1%\n",
      "[14/40] [Loss] train:0.011(f:-0.147+r:0.044+k:0.001+l:0.113) val:-0.348 test:-0.349 [Accr] train:18.8% val:94.3% test:94.1% maxVal:94.3% maxTest:94.1%\n",
      "[15/40] [Loss] train:0.010(f:-0.147+r:0.042+k:0.001+l:0.113) val:-0.354 test:-0.354 [Accr] train:18.8% val:94.4% test:94.4% maxVal:94.4% maxTest:94.4%\n",
      "[16/40] [Loss] train:0.007(f:-0.149+r:0.041+k:0.001+l:0.113) val:-0.362 test:-0.361 [Accr] train:18.9% val:94.6% test:94.5% maxVal:94.6% maxTest:94.5%\n",
      "[17/40] [Loss] train:0.005(f:-0.149+r:0.040+k:0.001+l:0.113) val:-0.360 test:-0.363 [Accr] train:18.9% val:94.6% test:94.6% maxVal:94.6% maxTest:94.5%\n",
      "[18/40] [Loss] train:0.003(f:-0.150+r:0.039+k:0.001+l:0.113) val:-0.364 test:-0.368 [Accr] train:18.9% val:94.7% test:94.8% maxVal:94.7% maxTest:94.8%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19/40] [Loss] train:0.001(f:-0.150+r:0.038+k:0.001+l:0.113) val:-0.368 test:-0.371 [Accr] train:18.9% val:94.9% test:95.2% maxVal:94.9% maxTest:95.2%\n",
      "[20/40] [Loss] train:0.001(f:-0.150+r:0.038+k:0.001+l:0.113) val:-0.368 test:-0.369 [Accr] train:19.0% val:94.9% test:95.1% maxVal:94.9% maxTest:95.2%\n",
      "[21/40] [Loss] train:0.000(f:-0.151+r:0.037+k:0.001+l:0.113) val:-0.371 test:-0.370 [Accr] train:18.9% val:94.7% test:95.1% maxVal:94.9% maxTest:95.2%\n",
      "[22/40] [Loss] train:0.000(f:-0.151+r:0.037+k:0.001+l:0.113) val:-0.368 test:-0.369 [Accr] train:18.9% val:94.9% test:95.0% maxVal:94.9% maxTest:95.2%\n",
      "[23/40] [Loss] train:-0.000(f:-0.151+r:0.037+k:0.001+l:0.113) val:-0.369 test:-0.370 [Accr] train:19.0% val:94.9% test:95.1% maxVal:94.9% maxTest:95.2%\n",
      "[24/40] [Loss] train:-0.000(f:-0.151+r:0.037+k:0.001+l:0.113) val:-0.374 test:-0.371 [Accr] train:18.9% val:94.9% test:95.1% maxVal:94.9% maxTest:95.2%\n",
      "[25/40] [Loss] train:-0.001(f:-0.152+r:0.037+k:0.001+l:0.113) val:-0.370 test:-0.369 [Accr] train:19.0% val:95.0% test:95.1% maxVal:95.0% maxTest:95.1%\n",
      "[26/40] [Loss] train:-0.001(f:-0.151+r:0.037+k:0.001+l:0.113) val:-0.371 test:-0.371 [Accr] train:19.0% val:94.9% test:95.1% maxVal:95.0% maxTest:95.1%\n",
      "[27/40] [Loss] train:-0.001(f:-0.152+r:0.037+k:0.001+l:0.113) val:-0.371 test:-0.376 [Accr] train:19.0% val:95.0% test:95.1% maxVal:95.0% maxTest:95.1%\n",
      "[28/40] [Loss] train:-0.002(f:-0.152+r:0.037+k:0.001+l:0.113) val:-0.374 test:-0.373 [Accr] train:19.0% val:95.0% test:95.1% maxVal:95.0% maxTest:95.1%\n",
      "[29/40] [Loss] train:-0.002(f:-0.153+r:0.037+k:0.001+l:0.113) val:-0.372 test:-0.372 [Accr] train:19.0% val:94.9% test:95.2% maxVal:95.0% maxTest:95.1%\n",
      "[30/40] [Loss] train:-0.002(f:-0.152+r:0.037+k:0.001+l:0.113) val:-0.377 test:-0.377 [Accr] train:19.0% val:94.9% test:95.1% maxVal:95.0% maxTest:95.1%\n",
      "[31/40] [Loss] train:-0.001(f:-0.152+r:0.037+k:0.001+l:0.113) val:-0.370 test:-0.369 [Accr] train:19.0% val:94.9% test:95.2% maxVal:95.0% maxTest:95.1%\n",
      "[32/40] [Loss] train:-0.002(f:-0.152+r:0.036+k:0.001+l:0.113) val:-0.372 test:-0.372 [Accr] train:19.0% val:95.0% test:95.2% maxVal:95.0% maxTest:95.1%\n",
      "[33/40] [Loss] train:-0.002(f:-0.152+r:0.037+k:0.001+l:0.113) val:-0.368 test:-0.370 [Accr] train:19.0% val:95.0% test:95.1% maxVal:95.0% maxTest:95.1%\n",
      "[34/40] [Loss] train:-0.001(f:-0.152+r:0.036+k:0.001+l:0.113) val:-0.370 test:-0.370 [Accr] train:19.0% val:94.8% test:95.1% maxVal:95.0% maxTest:95.1%\n",
      "[35/40] [Loss] train:-0.002(f:-0.152+r:0.037+k:0.001+l:0.113) val:-0.369 test:-0.372 [Accr] train:19.0% val:94.9% test:95.1% maxVal:95.0% maxTest:95.1%\n",
      "[36/40] [Loss] train:-0.002(f:-0.152+r:0.037+k:0.001+l:0.113) val:-0.370 test:-0.371 [Accr] train:19.0% val:94.9% test:95.1% maxVal:95.0% maxTest:95.1%\n",
      "[37/40] [Loss] train:-0.002(f:-0.152+r:0.037+k:0.001+l:0.113) val:-0.373 test:-0.374 [Accr] train:19.0% val:95.0% test:95.2% maxVal:95.0% maxTest:95.1%\n",
      "[38/40] [Loss] train:-0.002(f:-0.152+r:0.037+k:0.001+l:0.113) val:-0.373 test:-0.373 [Accr] train:19.0% val:94.9% test:95.1% maxVal:95.0% maxTest:95.1%\n",
      "[39/40] [Loss] train:-0.002(f:-0.152+r:0.037+k:0.001+l:0.113) val:-0.367 test:-0.368 [Accr] train:19.0% val:95.0% test:95.2% maxVal:95.0% maxTest:95.1%\n",
      "[40/40] [Loss] train:-0.002(f:-0.152+r:0.036+k:0.001+l:0.113) val:-0.375 test:-0.373 [Accr] train:19.0% val:94.9% test:95.1% maxVal:95.0% maxTest:95.1%\n",
      "Training finished.\n",
      "Extracting ../data/train-images-idx3-ubyte.gz\n",
      "Extracting ../data/train-labels-idx1-ubyte.gz\n",
      "Extracting ../data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ../data/t10k-labels-idx1-ubyte.gz\n",
      "Text name: ../res/res_mnist_rs_err90_basic_kmix15_choiceNet.txt\n",
      "[00/40] [Loss] train:0.053(f:-0.115+r:0.050+k:0.002+l:0.116) val:-0.062 test:-0.070 [Accr] train:15.7% val:63.8% test:65.9% maxVal:63.8% maxTest:65.9%\n",
      "[01/40] [Loss] train:0.045(f:-0.124+r:0.051+k:0.002+l:0.115) val:-0.151 test:-0.156 [Accr] train:17.2% val:79.2% test:80.3% maxVal:79.2% maxTest:80.3%\n",
      "[02/40] [Loss] train:0.040(f:-0.130+r:0.052+k:0.002+l:0.115) val:-0.207 test:-0.214 [Accr] train:17.8% val:85.0% test:85.9% maxVal:85.0% maxTest:85.9%\n",
      "[03/40] [Loss] train:0.037(f:-0.133+r:0.052+k:0.002+l:0.115) val:-0.230 test:-0.241 [Accr] train:18.0% val:87.9% test:88.4% maxVal:87.9% maxTest:88.4%\n",
      "[04/40] [Loss] train:0.033(f:-0.136+r:0.052+k:0.002+l:0.115) val:-0.252 test:-0.264 [Accr] train:18.2% val:89.7% test:90.1% maxVal:89.7% maxTest:90.1%\n",
      "[05/40] [Loss] train:0.031(f:-0.138+r:0.052+k:0.002+l:0.115) val:-0.270 test:-0.279 [Accr] train:18.3% val:90.8% test:91.1% maxVal:90.8% maxTest:91.1%\n",
      "[06/40] [Loss] train:0.029(f:-0.139+r:0.051+k:0.002+l:0.115) val:-0.284 test:-0.292 [Accr] train:18.4% val:92.0% test:91.9% maxVal:92.0% maxTest:91.9%\n",
      "[07/40] [Loss] train:0.026(f:-0.141+r:0.051+k:0.002+l:0.115) val:-0.299 test:-0.305 [Accr] train:18.5% val:92.8% test:92.6% maxVal:92.8% maxTest:92.6%\n",
      "[08/40] [Loss] train:0.024(f:-0.142+r:0.050+k:0.002+l:0.114) val:-0.310 test:-0.318 [Accr] train:18.6% val:93.1% test:93.2% maxVal:93.1% maxTest:93.2%\n",
      "[09/40] [Loss] train:0.023(f:-0.143+r:0.050+k:0.002+l:0.114) val:-0.317 test:-0.322 [Accr] train:18.6% val:93.4% test:93.5% maxVal:93.4% maxTest:93.5%\n",
      "[10/40] [Loss] train:0.020(f:-0.145+r:0.049+k:0.002+l:0.114) val:-0.325 test:-0.334 [Accr] train:18.7% val:94.0% test:94.0% maxVal:94.0% maxTest:94.0%\n",
      "[11/40] [Loss] train:0.019(f:-0.146+r:0.048+k:0.002+l:0.114) val:-0.328 test:-0.337 [Accr] train:18.7% val:93.9% test:94.3% maxVal:94.0% maxTest:94.0%\n",
      "[12/40] [Loss] train:0.016(f:-0.148+r:0.048+k:0.002+l:0.114) val:-0.340 test:-0.349 [Accr] train:18.8% val:94.1% test:94.4% maxVal:94.1% maxTest:94.4%\n",
      "[13/40] [Loss] train:0.015(f:-0.148+r:0.047+k:0.002+l:0.114) val:-0.343 test:-0.348 [Accr] train:18.9% val:94.5% test:94.8% maxVal:94.5% maxTest:94.8%\n",
      "[14/40] [Loss] train:0.013(f:-0.149+r:0.046+k:0.002+l:0.113) val:-0.349 test:-0.355 [Accr] train:18.9% val:94.7% test:94.9% maxVal:94.7% maxTest:94.9%\n",
      "[15/40] [Loss] train:0.011(f:-0.150+r:0.045+k:0.002+l:0.113) val:-0.356 test:-0.360 [Accr] train:18.9% val:94.8% test:95.1% maxVal:94.8% maxTest:95.1%\n",
      "[16/40] [Loss] train:0.009(f:-0.151+r:0.044+k:0.002+l:0.113) val:-0.355 test:-0.360 [Accr] train:18.9% val:94.8% test:95.0% maxVal:94.8% maxTest:95.1%\n",
      "[17/40] [Loss] train:0.007(f:-0.151+r:0.043+k:0.002+l:0.113) val:-0.361 test:-0.365 [Accr] train:19.0% val:94.8% test:95.1% maxVal:94.8% maxTest:95.1%\n",
      "[18/40] [Loss] train:0.005(f:-0.152+r:0.042+k:0.002+l:0.113) val:-0.368 test:-0.373 [Accr] train:19.0% val:95.1% test:95.4% maxVal:95.1% maxTest:95.4%\n",
      "[19/40] [Loss] train:0.004(f:-0.153+r:0.042+k:0.002+l:0.113) val:-0.364 test:-0.368 [Accr] train:19.0% val:95.3% test:95.5% maxVal:95.3% maxTest:95.5%\n",
      "[20/40] [Loss] train:0.003(f:-0.153+r:0.042+k:0.002+l:0.113) val:-0.368 test:-0.371 [Accr] train:19.1% val:95.2% test:95.5% maxVal:95.3% maxTest:95.5%\n",
      "[21/40] [Loss] train:0.002(f:-0.154+r:0.041+k:0.002+l:0.113) val:-0.374 test:-0.377 [Accr] train:19.0% val:95.1% test:95.4% maxVal:95.3% maxTest:95.5%\n",
      "[22/40] [Loss] train:0.002(f:-0.154+r:0.041+k:0.002+l:0.113) val:-0.373 test:-0.376 [Accr] train:19.0% val:95.2% test:95.4% maxVal:95.3% maxTest:95.5%\n",
      "[23/40] [Loss] train:0.002(f:-0.154+r:0.041+k:0.002+l:0.113) val:-0.370 test:-0.374 [Accr] train:19.1% val:95.2% test:95.5% maxVal:95.3% maxTest:95.5%\n",
      "[24/40] [Loss] train:0.002(f:-0.154+r:0.041+k:0.002+l:0.113) val:-0.370 test:-0.375 [Accr] train:19.0% val:95.3% test:95.5% maxVal:95.3% maxTest:95.5%\n",
      "[25/40] [Loss] train:0.002(f:-0.154+r:0.041+k:0.002+l:0.113) val:-0.371 test:-0.374 [Accr] train:19.1% val:95.3% test:95.5% maxVal:95.3% maxTest:95.5%\n",
      "[26/40] [Loss] train:0.001(f:-0.155+r:0.041+k:0.002+l:0.113) val:-0.373 test:-0.377 [Accr] train:19.1% val:95.2% test:95.4% maxVal:95.3% maxTest:95.5%\n",
      "[27/40] [Loss] train:0.001(f:-0.155+r:0.041+k:0.002+l:0.113) val:-0.372 test:-0.376 [Accr] train:19.1% val:95.2% test:95.5% maxVal:95.3% maxTest:95.5%\n",
      "[28/40] [Loss] train:0.001(f:-0.155+r:0.041+k:0.002+l:0.113) val:-0.369 test:-0.376 [Accr] train:19.1% val:95.1% test:95.5% maxVal:95.3% maxTest:95.5%\n",
      "[29/40] [Loss] train:0.001(f:-0.154+r:0.041+k:0.002+l:0.113) val:-0.368 test:-0.373 [Accr] train:19.1% val:95.2% test:95.5% maxVal:95.3% maxTest:95.5%\n",
      "[30/40] [Loss] train:0.001(f:-0.155+r:0.041+k:0.002+l:0.113) val:-0.373 test:-0.375 [Accr] train:19.1% val:95.3% test:95.5% maxVal:95.3% maxTest:95.5%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[31/40] [Loss] train:0.001(f:-0.155+r:0.041+k:0.002+l:0.113) val:-0.371 test:-0.375 [Accr] train:19.1% val:95.2% test:95.5% maxVal:95.3% maxTest:95.5%\n",
      "[32/40] [Loss] train:0.001(f:-0.155+r:0.041+k:0.002+l:0.113) val:-0.372 test:-0.376 [Accr] train:19.1% val:95.2% test:95.5% maxVal:95.3% maxTest:95.5%\n",
      "[33/40] [Loss] train:0.000(f:-0.155+r:0.041+k:0.002+l:0.113) val:-0.372 test:-0.376 [Accr] train:19.1% val:95.2% test:95.5% maxVal:95.3% maxTest:95.5%\n",
      "[34/40] [Loss] train:0.001(f:-0.155+r:0.041+k:0.002+l:0.113) val:-0.371 test:-0.375 [Accr] train:19.1% val:95.2% test:95.6% maxVal:95.3% maxTest:95.5%\n",
      "[35/40] [Loss] train:0.001(f:-0.155+r:0.041+k:0.002+l:0.113) val:-0.367 test:-0.374 [Accr] train:19.1% val:95.2% test:95.5% maxVal:95.3% maxTest:95.5%\n",
      "[36/40] [Loss] train:0.000(f:-0.155+r:0.041+k:0.002+l:0.113) val:-0.370 test:-0.373 [Accr] train:19.1% val:95.2% test:95.6% maxVal:95.3% maxTest:95.5%\n",
      "[37/40] [Loss] train:0.001(f:-0.155+r:0.041+k:0.002+l:0.113) val:-0.371 test:-0.377 [Accr] train:19.1% val:95.2% test:95.6% maxVal:95.3% maxTest:95.5%\n",
      "[38/40] [Loss] train:0.001(f:-0.155+r:0.041+k:0.002+l:0.113) val:-0.368 test:-0.371 [Accr] train:19.1% val:95.2% test:95.5% maxVal:95.3% maxTest:95.5%\n",
      "[39/40] [Loss] train:0.001(f:-0.155+r:0.041+k:0.002+l:0.113) val:-0.367 test:-0.373 [Accr] train:19.1% val:95.3% test:95.6% maxVal:95.3% maxTest:95.5%\n",
      "[40/40] [Loss] train:0.000(f:-0.155+r:0.041+k:0.002+l:0.113) val:-0.373 test:-0.375 [Accr] train:19.1% val:95.2% test:95.6% maxVal:95.3% maxTest:95.5%\n",
      "Training finished.\n",
      "Extracting ../data/train-images-idx3-ubyte.gz\n",
      "Extracting ../data/train-labels-idx1-ubyte.gz\n",
      "Extracting ../data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ../data/t10k-labels-idx1-ubyte.gz\n",
      "Text name: ../res/res_mnist_rs_err90_basic_kmix20_choiceNet.txt\n",
      "[00/40] [Loss] train:0.053(f:-0.116+r:0.050+k:0.003+l:0.116) val:-0.067 test:-0.076 [Accr] train:15.9% val:66.5% test:68.1% maxVal:66.5% maxTest:68.1%\n",
      "[01/40] [Loss] train:0.045(f:-0.125+r:0.052+k:0.003+l:0.115) val:-0.154 test:-0.162 [Accr] train:17.2% val:80.0% test:80.6% maxVal:80.0% maxTest:80.6%\n",
      "[02/40] [Loss] train:0.041(f:-0.130+r:0.053+k:0.003+l:0.115) val:-0.202 test:-0.210 [Accr] train:17.8% val:86.0% test:86.4% maxVal:86.0% maxTest:86.4%\n",
      "[03/40] [Loss] train:0.038(f:-0.133+r:0.053+k:0.003+l:0.115) val:-0.233 test:-0.241 [Accr] train:18.1% val:88.7% test:88.8% maxVal:88.7% maxTest:88.8%\n",
      "[04/40] [Loss] train:0.034(f:-0.136+r:0.052+k:0.003+l:0.115) val:-0.254 test:-0.263 [Accr] train:18.3% val:90.5% test:90.7% maxVal:90.5% maxTest:90.7%\n",
      "[05/40] [Loss] train:0.032(f:-0.138+r:0.052+k:0.003+l:0.115) val:-0.273 test:-0.278 [Accr] train:18.3% val:91.6% test:91.6% maxVal:91.6% maxTest:91.6%\n",
      "[06/40] [Loss] train:0.029(f:-0.140+r:0.052+k:0.003+l:0.115) val:-0.290 test:-0.296 [Accr] train:18.4% val:92.5% test:92.7% maxVal:92.5% maxTest:92.7%\n",
      "[07/40] [Loss] train:0.027(f:-0.142+r:0.051+k:0.003+l:0.115) val:-0.301 test:-0.307 [Accr] train:18.6% val:93.0% test:93.1% maxVal:93.0% maxTest:93.1%\n",
      "[08/40] [Loss] train:0.025(f:-0.143+r:0.051+k:0.003+l:0.114) val:-0.310 test:-0.316 [Accr] train:18.6% val:93.4% test:93.5% maxVal:93.4% maxTest:93.5%\n",
      "[09/40] [Loss] train:0.023(f:-0.144+r:0.050+k:0.003+l:0.114) val:-0.319 test:-0.324 [Accr] train:18.6% val:93.8% test:93.8% maxVal:93.8% maxTest:93.8%\n",
      "[10/40] [Loss] train:0.021(f:-0.145+r:0.049+k:0.003+l:0.114) val:-0.326 test:-0.332 [Accr] train:18.7% val:94.1% test:94.2% maxVal:94.1% maxTest:94.2%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Worker_00:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"<string>\", line 26, in run\n",
      "  File \"<string>\", line 28, in train_wrapper_mnist\n",
      "  File \"<string>\", line 416, in train\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\", line 900, in run\n",
      "    run_metadata_ptr)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\", line 1135, in _run\n",
      "    feed_dict_tensor, options, run_metadata)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\", line 1316, in _do_run\n",
      "    run_metadata)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\", line 1322, in _do_call\n",
      "    return fn(*args)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\", line 1307, in _run_fn\n",
      "    options, feed_dict, fetch_list, target_list, run_metadata)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\", line 1409, in _call_tf_sessionrun\n",
      "    run_metadata)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "for i in range(nWorker):\n",
    "    WORKERS[i].start(); # Start process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
